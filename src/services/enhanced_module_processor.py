'''
ARQV30 Enhanced v3.0 - Enhanced Module Processor
Processador aprimorado de m√≥dulos com IA e integra√ß√£o com Synthesis Engine
IMPLEMENTA√á√ÉO COMPLETA PARA RELAT√ìRIOS COERENTES E ESPECIALIZADOS
'''

import os
import logging
import asyncio
import json
import re
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path

# Import do Enhanced AI Manager e Synthesis Engine
from services.enhanced_ai_manager import enhanced_ai_manager
from services.auto_save_manager import salvar_etapa, salvar_erro

# Configura√ß√£o do diret√≥rio base de forma mais robusta
# Idealmente, isso viria de uma configura√ß√£o centralizada ou vari√°vel de ambiente
BASE_DATA_DIR = Path(os.getenv("ARQV30_DATA_DIR", Path(__file__).parent.parent / "analyses_data"))

# Configura√ß√£o do Logger
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Importa√ß√£o segura de m√≥dulos aprimorados
try:
    from services.cpl_devastador_protocol import CPLDevastadorProtocol
    from services.avatar_generation_system import AvatarGenerationSystem
    from services.visceral_leads_engineer import VisceralLeadsEngineer
    HAS_ENHANCED_MODULES = True
    logger.info("M√≥dulos aprimorados (CPL, Avatar, Visceral) carregados com sucesso.")
except ImportError as e:
    logger.warning(f"Um ou mais m√≥dulos aprimorados n√£o foram encontrados. O sistema operar√° em modo padr√£o. Detalhe: {e}")
    CPLDevastadorProtocol = None
    AvatarGenerationSystem = None
    VisceralLeadsEngineer = None
    HAS_ENHANCED_MODULES = False

logger.info("üöÄ ARQV30 Enhanced v3.0 - Processador de M√≥dulos Iniciado")

class EnhancedModuleProcessor:
    '''
    Processador aprimorado de m√≥dulos com foco em resultados precisos e coerentes
    INTEGRA√á√ÉO COMPLETA COM SYNTHESIS ENGINE PARA RELAT√ìRIOS ESPECIALIZADOS
    '''

    def __init__(self):
        '''Inicializa o processador com integra√ß√£o ao Synthesis Engine'''
        self.ai_manager = enhanced_ai_manager
        self.modules_config = self._get_consolidated_modules_config()
        
        # Integra√ß√£o com Synthesis Engine
        self.synthesis_integration = True
        self.content_quality_threshold = 0.8
        self.coherence_validation = True
        
        # M√©tricas de qualidade dos m√≥dulos
        self.module_quality_metrics = {
            'total_generated': 0,
            'high_quality_modules': 0,
            'coherence_score': 0.0,
            'synthesis_alignment': 0.0
        }
        
        logger.info("üöÄ Enhanced Module Processor ULTRA-ROBUSTO inicializado")
        logger.info(f"üìä {len(self.modules_config)} m√≥dulos especializados configurados")
        logger.info("üîó Integra√ß√£o com Synthesis Engine ativada")
        logger.info("‚úÖ Valida√ß√£o de coer√™ncia habilitada")

    def _get_consolidated_modules_config(self) -> Dict[str, Any]:
        '''Retorna a configura√ß√£o consolidada e sem duplicatas dos m√≥dulos.'''
        # M√≥dulos foram revisados para eliminar redund√¢ncias e melhorar a clareza.
        return {
            'sintese_master': {
                'title': 'S√≠ntese Master do Projeto',
                'description': 'Vis√£o geral consolidada do projeto, unificando os principais pontos do briefing e contexto estrat√©gico.',
                'use_active_search': False,
                'type': 'core'
            },
            'avatares': {
                'title': 'Avatares Detalhados do P√∫blico-Alvo',
                'description': 'Cria√ß√£o de personas detalhadas do p√∫blico-alvo, incluindo dores, desejos, demografia e comportamento.',
                'use_active_search': False,
                'type': 'core'
            },
            'analise_competitiva': {
                'title': 'An√°lise Competitiva Aprofundada',
                'description': 'Mapeamento e an√°lise completa dos principais concorrentes diretos e indiretos.',
                'use_active_search': True,
                'type': 'research'
            },
            'insights_mercado': {
                'title': 'Insights Estrat√©gicos de Mercado',
                'description': 'An√°lise de tend√™ncias, oportunidades, riscos e din√¢mica do mercado para informar a estrat√©gia.',
                'use_active_search': True,
                'type': 'research'
            },
            'posicionamento': {
                'title': 'Estrat√©gia de Posicionamento e Diferencia√ß√£o',
                'description': 'Defini√ß√£o do posicionamento √∫nico da marca/produto no mercado e seus principais diferenciais.',
                'use_active_search': False,
                'type': 'strategy'
            },
            'drivers_mentais': {
                'title': 'Drivers Mentais e Gatilhos Psicol√≥gicos',
                'description': 'Identifica√ß√£o dos principais gatilhos psicol√≥gicos e drivers de compra do p√∫blico-alvo.',
                'use_active_search': False,
                'type': 'strategy'
            },
            'estrategia_conteudo': {
                'title': 'Estrat√©gia de Marketing de Conte√∫do',
                'description': 'Planejamento de conte√∫do para atrair, engajar e converter o p√∫blico-alvo em diferentes etapas do funil.',
                'use_active_search': True,
                'type': 'strategy'
            },
            'funil_vendas': {
                'title': 'Estrutura do Funil de Vendas',
                'description': 'Desenho da jornada do cliente e da estrutura completa do funil de vendas, da atra√ß√£o √† convers√£o.',
                'use_active_search': False,
                'type': 'strategy'
            },
            'canais_aquisicao': {
                'title': 'Mapeamento de Canais de Aquisi√ß√£o',
                'description': 'Identifica√ß√£o e prioriza√ß√£o dos canais de aquisi√ß√£o de clientes mais eficazes para o neg√≥cio.',
                'use_active_search': False,
                'type': 'strategy'
            },
            'estrategia_preco': {
                'title': 'Estrat√©gia de Precifica√ß√£o e Monetiza√ß√£o',
                'description': 'Defini√ß√£o de modelos de pre√ßo, propostas de valor e estrat√©gias de monetiza√ß√£o.',
                'use_active_search': False,
                'type': 'strategy'
            },
            'copy_devastadora': {
                'title': 'Diretrizes de Copywriting de Alta Convers√£o',
                'description': 'Cria√ß√£o de diretrizes e exemplos de copywriting com foco em persuas√£o e convers√£o.',
                'use_active_search': False,
                'type': 'execution'
            },
            'provas_visuais': {
                'title': 'Sistema de Provas Visuais e Sociais',
                'description': 'Estrat√©gia para coletar e apresentar provas sociais e visuais para construir credibilidade.',
                'use_active_search': False,
                'type': 'execution'
            },
            'anti_objecao': {
                'title': 'Sistema Anti-Obje√ß√£o',
                'description': 'Mapeamento de poss√≠veis obje√ß√µes e desenvolvimento de argumentos para neutraliz√°-las.',
                'use_active_search': False,
                'type': 'execution'
            },
            'plano_acao': {
                'title': 'Plano de A√ß√£o Execut√°vel',
                'description': 'Cria√ß√£o de um plano de a√ß√£o detalhado com fases, tarefas e cronograma para implementa√ß√£o.',
                'use_active_search': False,
                'type': 'execution'
            },
            'metricas_kpis': {
                'title': 'Defini√ß√£o de M√©tricas e KPIs',
                'description': 'Sele√ß√£o dos principais indicadores de desempenho (KPIs) para monitorar o sucesso do projeto.',
                'use_active_search': False,
                'type': 'execution'
            },
            'cronograma_lancamento': {
                'title': 'Cronograma Detalhado de Lan√ßamento',
                'description': 'Elabora√ß√£o de um cronograma detalhado para as fases de um lan√ßamento de produto/servi√ßo.',
                'use_active_search': False,
                'type': 'execution'
            },
            'cpl_completo': {
                'title': 'Protocolo Integrado de CPLs Devastadores',
                'description': 'Protocolo completo para cria√ß√£o de uma sequ√™ncia de 4 CPLs (Conte√∫do Pr√©-Lan√ßamento) de alta performance.',
                'use_active_search': True,
                'type': 'specialized',
                'requires': ['sintese_master', 'avatares', 'posicionamento', 'insights_mercado']
            },
            'ai_verification': {
                'title': 'Verifica√ß√£o por IA - Etapa de Qualidade',
                'description': 'Verifica√ß√£o autom√°tica de qualidade, consist√™ncia e confiabilidade dos dados gerados.',
                'use_active_search': False,
                'type': 'verification'
            }
        }

    async def generate_modules_with_synthesis_integration(self, session_id: str, synthesis_data: Dict[str, Any] = None) -> Dict[str, Any]:
        '''
        Gera m√≥dulos com integra√ß√£o completa ao Synthesis Engine
        M√âTODO PRINCIPAL PARA GERA√á√ÉO DE RELAT√ìRIOS COERENTES
        '''
        logger.info(f"üß† Iniciando gera√ß√£o de m√≥dulos com integra√ß√£o Synthesis Engine: {session_id}")
        
        try:
            # ETAPA 1: Carregar e validar dados base
            base_data = await self._load_and_validate_base_data(session_id, synthesis_data)
            if not base_data:
                return self._create_error_result(session_id, "Falha ao carregar dados base")
            
            # ETAPA 2: An√°lise de coer√™ncia dos dados
            coherence_analysis = await self._analyze_data_coherence(base_data, session_id)
            
            # ETAPA 3: Prepara√ß√£o do contexto especializado
            specialized_context = await self._prepare_specialized_context(base_data, coherence_analysis)
            
            # ETAPA 4: Gera√ß√£o sequencial de m√≥dulos com valida√ß√£o
            results = await self._generate_modules_with_validation(session_id, specialized_context)
            
            # ETAPA 5: Valida√ß√£o final de coer√™ncia entre m√≥dulos
            final_validation = await self._validate_module_coherence(session_id, results)
            
            # ETAPA 6: Aprimoramento baseado na valida√ß√£o
            if final_validation['needs_improvement']:
                results = await self._improve_module_quality(session_id, results, final_validation)
            
            # Atualizar m√©tricas
            self._update_quality_metrics(results, final_validation)
            
            logger.info(f"‚úÖ Gera√ß√£o completa para sess√£o {session_id}")
            logger.info(f"üìä Qualidade geral: {final_validation.get('overall_quality', 0):.1f}/100")
            
            return {
                **results,
                'synthesis_integration': True,
                'quality_metrics': final_validation,
                'coherence_score': coherence_analysis.get('coherence_score', 0)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o com integra√ß√£o Synthesis: {e}")
            salvar_erro("module_generation_synthesis_error", str(e), contexto={'session_id': session_id})
            return self._create_error_result(session_id, str(e))

    async def _load_and_validate_base_data(self, session_id: str, synthesis_data: Dict[str, Any] = None) -> Optional[Dict[str, Any]]:
        '''Carrega e valida dados base com integra√ß√£o do Synthesis Engine'''
        try:
            logger.info("üìä Carregando e validando dados base")
            
            # Carregar dados tradicionais
            base_data = self._load_base_data(session_id)
            
            # Integrar dados do Synthesis Engine se dispon√≠veis
            if synthesis_data:
                base_data = self._integrate_synthesis_data(base_data, synthesis_data)
                logger.info("üîó Dados do Synthesis Engine integrados")
            
            # Validar qualidade dos dados
            validation_result = await self._validate_base_data_quality(base_data)
            
            if validation_result['is_valid']:
                logger.info(f"‚úÖ Dados base validados - Qualidade: {validation_result['quality_score']:.2f}")
                base_data['validation_result'] = validation_result
                return base_data
            else:
                logger.error(f"‚ùå Dados base inv√°lidos: {validation_result['issues']}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar dados base: {e}")
            return None

    def _integrate_synthesis_data(self, base_data: Dict[str, Any], synthesis_data: Dict[str, Any]) -> Dict[str, Any]:
        '''Integra dados do Synthesis Engine aos dados base'''
        try:
            if not base_data:
                base_data = {}
            
            # Integrar s√≠ntese principal
            if 'synthesis' in synthesis_data:
                base_data['synthesis_master'] = synthesis_data['synthesis']
            
            # Integrar m√©tricas de qualidade
            if 'quality_metrics' in synthesis_data:
                base_data['quality_metrics'] = synthesis_data['quality_metrics']
            
            # Integrar query original
            if 'query_original' in synthesis_data:
                base_data['query_original'] = synthesis_data['query_original']
            
            # Marcar como integrado
            base_data['synthesis_integrated'] = True
            base_data['integration_timestamp'] = datetime.now().isoformat()
            
            return base_data
            
        except Exception as e:
            logger.error(f"‚ùå Erro na integra√ß√£o de dados: {e}")
            return base_data

    async def _validate_base_data_quality(self, base_data: Dict[str, Any]) -> Dict[str, Any]:
        '''Valida a qualidade dos dados base'''
        try:
            validation_result = {
                'is_valid': False,
                'quality_score': 0.0,
                'issues': [],
                'strengths': []
            }
            
            # Verificar presen√ßa de dados essenciais
            essential_fields = ['contexto_estrategico', 'sintese_master']
            missing_fields = [field for field in essential_fields if field not in base_data]
            
            if missing_fields:
                validation_result['issues'].append(f"Campos essenciais ausentes: {missing_fields}")
            else:
                validation_result['strengths'].append("Todos os campos essenciais presentes")
            
            # Verificar qualidade do contexto estrat√©gico
            if 'contexto_estrategico' in base_data:
                context = base_data['contexto_estrategico']
                if context.get('tema') and context.get('segmento'):
                    validation_result['strengths'].append("Contexto estrat√©gico bem definido")
                else:
                    validation_result['issues'].append("Contexto estrat√©gico incompleto")
            
            # Verificar integra√ß√£o com Synthesis Engine
            if base_data.get('synthesis_integrated'):
                validation_result['strengths'].append("Integra√ß√£o com Synthesis Engine ativa")
            
            # Calcular pontua√ß√£o de qualidade
            total_checks = len(essential_fields) + 2  # campos essenciais + contexto + synthesis
            passed_checks = len(validation_result['strengths'])
            validation_result['quality_score'] = passed_checks / total_checks
            
            # Determinar se √© v√°lido
            validation_result['is_valid'] = validation_result['quality_score'] >= 0.6
            
            return validation_result
            
        except Exception as e:
            logger.error(f"‚ùå Erro na valida√ß√£o de dados: {e}")
            return {'is_valid': False, 'quality_score': 0.0, 'issues': [str(e)]}

    async def _analyze_data_coherence(self, base_data: Dict[str, Any], session_id: str) -> Dict[str, Any]:
        '''Analisa a coer√™ncia dos dados para gera√ß√£o de m√≥dulos'''
        try:
            logger.info("üîç Analisando coer√™ncia dos dados")
            
            coherence_analysis = {
                'coherence_score': 0.0,
                'consistency_issues': [],
                'data_gaps': [],
                'recommendations': []
            }
            
            # Verificar consist√™ncia entre contexto e s√≠ntese
            context = base_data.get('contexto_estrategico', {})
            synthesis = base_data.get('sintese_master', {})
            
            # Verificar alinhamento de tema/segmento
            context_tema = context.get('tema', '').lower()
            synthesis_insights = str(synthesis.get('insights_principais', [])).lower()
            
            if context_tema and context_tema in synthesis_insights:
                coherence_analysis['coherence_score'] += 0.3
            else:
                coherence_analysis['consistency_issues'].append("Desalinhamento entre tema do contexto e insights")
            
            # Verificar presen√ßa de p√∫blico-alvo
            if synthesis.get('publico_alvo_refinado'):
                coherence_analysis['coherence_score'] += 0.3
            else:
                coherence_analysis['data_gaps'].append("P√∫blico-alvo n√£o definido na s√≠ntese")
            
            # Verificar oportunidades identificadas
            opportunities = synthesis.get('oportunidades_identificadas', [])
            if len(opportunities) >= 5:
                coherence_analysis['coherence_score'] += 0.4
            else:
                coherence_analysis['data_gaps'].append("Poucas oportunidades identificadas")
            
            # Gerar recomenda√ß√µes
            if coherence_analysis['coherence_score'] < 0.7:
                coherence_analysis['recommendations'].append("Enriquecer dados com busca ativa")
                coherence_analysis['recommendations'].append("Validar alinhamento entre contexto e s√≠ntese")
            
            logger.info(f"üìä Coer√™ncia dos dados: {coherence_analysis['coherence_score']:.2f}")
            return coherence_analysis
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise de coer√™ncia: {e}")
            return {'coherence_score': 0.0, 'consistency_issues': [str(e)]}

    async def _prepare_specialized_context(self, base_data: Dict[str, Any], coherence_analysis: Dict[str, Any]) -> Dict[str, Any]:
        '''Prepara contexto especializado para gera√ß√£o de m√≥dulos'''
        try:
            logger.info("üéØ Preparando contexto especializado")
            
            specialized_context = {
                'base_data': base_data,
                'coherence_analysis': coherence_analysis,
                'module_guidelines': self._get_module_guidelines(),
                'quality_requirements': self._get_quality_requirements(),
                'cross_module_references': {}
            }
            
            # Extrair elementos-chave para refer√™ncia cruzada
            synthesis = base_data.get('sintese_master', {})
            
            specialized_context['key_insights'] = synthesis.get('insights_principais', [])[:10]
            specialized_context['target_audience'] = synthesis.get('publico_alvo_refinado', {})
            specialized_context['market_opportunities'] = synthesis.get('oportunidades_identificadas', [])[:8]
            specialized_context['query_original'] = base_data.get('query_original', '')
            
            # Preparar diretrizes espec√≠ficas por tipo de m√≥dulo
            specialized_context['module_specific_guidelines'] = {
                'avatar': self._get_avatar_guidelines(specialized_context),
                'competitive': self._get_competitive_guidelines(specialized_context),
                'strategy': self._get_strategy_guidelines(specialized_context),
                'content': self._get_content_guidelines(specialized_context)
            }
            
            logger.info("‚úÖ Contexto especializado preparado")
            return specialized_context
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao preparar contexto: {e}")
            return {'base_data': base_data, 'error': str(e)}

    def _get_module_guidelines(self) -> Dict[str, str]:
        '''Retorna diretrizes gerais para gera√ß√£o de m√≥dulos'''
        return {
            'focus_on_query': 'Mantenha foco absoluto na query original',
            'use_real_data': 'Use apenas dados reais extra√≠dos da coleta',
            'be_specific': 'Seja espec√≠fico e acion√°vel em todas as recomenda√ß√µes',
            'maintain_coherence': 'Mantenha coer√™ncia com outros m√≥dulos',
            'validate_sources': 'Valide informa√ß√µes com fontes confi√°veis'
        }

    def _get_quality_requirements(self) -> Dict[str, Any]:
        '''Retorna requisitos de qualidade para m√≥dulos'''
        return {
            'min_content_length': 800,
            'max_generic_content': 0.2,
            'required_specificity': 0.8,
            'coherence_threshold': 0.7,
            'actionability_score': 0.8
        }

    def _get_avatar_guidelines(self, context: Dict[str, Any]) -> str:
        '''Diretrizes espec√≠ficas para m√≥dulos de avatar'''
        target_audience = context.get('target_audience', {})
        return f"""
        DIRETRIZES PARA AVATAR:
        - Base-se nos dados demogr√°ficos: {target_audience.get('demografia_detalhada', {})}
        - Use as dores viscerais identificadas: {target_audience.get('dores_viscerais_reais', [])}
        - Incorpore os desejos ardentes: {target_audience.get('desejos_ardentes_reais', [])}
        - Mantenha foco na query original: {context.get('query_original', '')}
        """

    def _get_competitive_guidelines(self, context: Dict[str, Any]) -> str:
        '''Diretrizes espec√≠ficas para an√°lise competitiva'''
        opportunities = context.get('market_opportunities', [])
        return f"""
        DIRETRIZES PARA AN√ÅLISE COMPETITIVA:
        - Explore as oportunidades identificadas: {opportunities}
        - Use dados reais de mercado da s√≠ntese
        - Identifique gaps competitivos espec√≠ficos
        - Foque no contexto da query original
        """

    def _get_strategy_guidelines(self, context: Dict[str, Any]) -> str:
        '''Diretrizes espec√≠ficas para estrat√©gias'''
        insights = context.get('key_insights', [])
        return f"""
        DIRETRIZES PARA ESTRAT√âGIAS:
        - Base estrat√©gias nos insights principais: {insights}
        - Seja espec√≠fico e acion√°vel
        - Inclua m√©tricas mensur√°veis
        - Mantenha alinhamento com a query original
        """

    def _get_content_guidelines(self, context: Dict[str, Any]) -> str:
        '''Diretrizes espec√≠ficas para conte√∫do'''
        return f"""
        DIRETRIZES PARA CONTE√öDO:
        - Use linguagem do p√∫blico-alvo identificado
        - Incorpore insights comportamentais da s√≠ntese
        - Seja espec√≠fico ao contexto da query
        - Inclua exemplos pr√°ticos e acion√°veis
        """

    def _create_error_result(self, session_id: str, error_message: str) -> Dict[str, Any]:
        '''Cria resultado de erro padronizado'''
        return {
            "session_id": session_id,
            "error": error_message,
            "successful_modules": 0,
            "failed_modules": len(self.modules_config),
            "modules_generated": [],
            "modules_failed": list(self.modules_config.keys()),
            "total_modules": len(self.modules_config),
            "synthesis_integration": False
        }

    async def generate_all_modules(self, session_id: str) -> Dict[str, Any]:
        '''Gera todos os m√≥dulos configurados de forma sequencial e robusta.'''
        logger.info(f"üöÄ Iniciando gera√ß√£o de todos os m√≥dulos para a sess√£o: {session_id}")

        base_data = self._load_base_data(session_id)
        if not base_data:
            logger.error(f"N√£o foi poss√≠vel carregar os dados base para a sess√£o {session_id}. Abortando a gera√ß√£o de m√≥dulos.")
            return {
                "session_id": session_id,
                "error": "Falha ao carregar dados base.",
                "successful_modules": 0,
                "failed_modules": len(self.modules_config),
                "modules_generated": [],
                "modules_failed": list(self.modules_config.keys()),
                "total_modules": len(self.modules_config)
            }

        results = {
            "session_id": session_id,
            "successful_modules": 0,
            "failed_modules": 0,
            "modules_generated": [],
            "modules_failed": [],
            "total_modules": len(self.modules_config)
        }

        modules_dir = BASE_DATA_DIR / session_id / "modules"
        modules_dir.mkdir(parents=True, exist_ok=True)

        for module_name, config in self.modules_config.items():
            try:
                logger.info(f"üìù Gerando m√≥dulo: {config['title']} ({module_name})")
                
                # Passa os dados j√° gerados como contexto para os m√≥dulos seguintes
                context_from_previous_modules = self._get_context_from_generated_modules(results['modules_generated'], modules_dir)

                if module_name == 'cpl_completo' and CPLDevastadorProtocol:
                    module_content = await self._generate_cpl_module(base_data, session_id)
                else:
                    module_content = await self._generate_standard_module(module_name, config, base_data, context_from_previous_modules, session_id)

                if module_content:
                    file_extension = "json" if module_name == 'cpl_completo' else "md"
                    module_path = modules_dir / f"{module_name}.{file_extension}"
                    with open(module_path, 'w', encoding='utf-8') as f:
                        if file_extension == "json":
                            json.dump(module_content, f, indent=4, ensure_ascii=False)
                        else:
                            f.write(module_content)
                    
                    results["successful_modules"] += 1
                    results["modules_generated"].append(module_name)
                    logger.info(f"‚úÖ M√≥dulo {module_name} gerado com sucesso.")
                    salvar_etapa(f"geracao_modulo_{module_name}", {"status": "sucesso", "path": str(module_path)})
                else:
                    raise ValueError("Conte√∫do do m√≥dulo retornado como vazio.")

            except Exception as e:
                logger.error(f"‚ùå Erro ao gerar m√≥dulo {module_name}: {e}", exc_info=True)
                salvar_erro(f"geracao_modulo_{module_name}", str(e), contexto={"session_id": session_id})
                results["failed_modules"] += 1
                results["modules_failed"].append({"module": module_name, "error": str(e)})

        await self._generate_consolidated_report(session_id, results)
        logger.info(f"üèÅ Processo finalizado para a sess√£o {session_id}. Sucesso: {results['successful_modules']}, Falhas: {results['failed_modules']}.")
        return results

    async def _generate_cpl_module(self, base_data: Dict[str, Any], session_id: str) -> Dict[str, Any]:
        '''Gera o conte√∫do para o m√≥dulo especializado CPL.'''
        if not CPLDevastadorProtocol:
            logger.warning("Protocolo CPL n√£o dispon√≠vel, usando conte√∫do de fallback.")
            return {
                'titulo': 'Protocolo de CPLs Devastadores (Fallback)',
                'descricao': 'O m√≥dulo especializado para CPL n√£o p√¥de ser carregado. Este √© um conte√∫do substituto.',
                'status': 'fallback'
            }

        cpl_protocol = CPLDevastadorProtocol()
        contexto = base_data.get('contexto_estrategico', {})
        
        return await cpl_protocol.executar_protocolo_completo(
            tema=contexto.get('tema', 'N√£o especificado'),
            segmento=contexto.get('segmento', 'N√£o especificado'),
            publico_alvo=contexto.get('publico_alvo', 'N√£o especificado'),
            session_id=session_id
        )

    async def _generate_standard_module(self, module_name: str, config: Dict[str, Any], base_data: Dict[str, Any], context_from_previous: str, session_id: str) -> str:
        '''Gera o conte√∫do para um m√≥dulo padr√£o.'''
        prompt = self._get_module_prompt(module_name, config, base_data, context_from_previous)
        
        if config.get('use_active_search', False):
            # O contexto para a busca ativa deve ser conciso
            search_context = f"Projeto: {base_data.get('contexto_estrategico', {}).get('tema', '')}. Mercado: {base_data.get('contexto_estrategico', {}).get('segmento', '')}."
            content = await self.ai_manager.generate_with_active_search(
                prompt=prompt,
                context=search_context,
                session_id=session_id
            )
        else:
            content = await self.ai_manager.generate_text(prompt=prompt)

        if self._is_ai_refusal(content) or not content or len(content.strip()) < 150:
            logger.warning(f"‚ö†Ô∏è Conte√∫do da IA insuficiente ou recusado para {module_name}. Gerando fallback robusto.")
            content = self._generate_fallback_content(module_name, config, base_data)
        
        return content

    def _load_base_data(self, session_id: str) -> Dict[str, Any]:
        '''Carrega os dados base da sess√£o (sintese_master, contexto_estrategico, etc.).'''
        try:
            sintese_master_path = BASE_DATA_DIR / session_id / "sintese_master.json"
            contexto_path = BASE_DATA_DIR / session_id / "contexto_estrategico.json"

            base_data = {}
            if sintese_master_path.exists():
                with open(sintese_master_path, 'r', encoding='utf-8') as f:
                    base_data['sintese_master'] = json.load(f)
            
            if contexto_path.exists():
                with open(contexto_path, 'r', encoding='utf-8') as f:
                    base_data['contexto_estrategico'] = json.load(f)

            if not base_data:
                logger.warning(f"Nenhum dado base (sintese_master, contexto_estrategico) encontrado para a sess√£o {session_id}.")
                return None

            logger.info(f"Dados base carregados para a sess√£o {session_id}.")
            return base_data
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar dados base para sess√£o {session_id}: {e}", exc_info=True)
            return None

    def _get_context_from_generated_modules(self, generated_modules: List[str], modules_dir: Path) -> str:
        '''Constr√≥i um contexto com base nos resumos dos m√≥dulos j√° gerados.'''
        context = "\n\n---\nCONTEXTO DOS M√ìDULOS ANTERIORES:\n"
        for module_name in generated_modules:
            try:
                module_file = modules_dir / f"{module_name}.md"
                if module_file.exists():
                    with open(module_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        # Extrai o resumo executivo ou as primeiras linhas
                        summary = self._extract_summary(content)
                        context += f"\n### Resumo do M√≥dulo: {self.modules_config[module_name]['title']}\n{summary}\n"
            except Exception as e:
                logger.warning(f"N√£o foi poss√≠vel ler o m√≥dulo anterior {module_name} para gerar contexto: {e}")
        return context

    def _extract_summary(self, content: str) -> str:
        '''Extrai um resumo de um conte√∫do de m√≥dulo.'''
        # Tenta encontrar um "Resumo Executivo"
        try:
            parts = content.split("## Resumo Executivo")
            if len(parts) > 1:
                summary_part = parts[1].split("## ")[0]
                return "\n".join(summary_part.strip().split('\n')[:5]) # Limita a 5 linhas
        except Exception:
            pass # Ignora erros e usa o m√©todo fallback
        
        # Se n√£o encontrar, retorna as primeiras 7 linhas do arquivo
        return "\n".join(content.strip().split('\n')[:7])

    def _get_module_prompt(self, module_name: str, config: Dict[str, Any], base_data: Dict[str, Any], context_from_previous: str) -> str:
        '''Cria um prompt detalhado e focado para a IA, evitando alucina√ß√µes.'''
        contexto_estrategico = base_data.get('contexto_estrategico', {})
        tema = contexto_estrategico.get('tema', 'o projeto')
        segmento = contexto_estrategico.get('segmento', 'o mercado')
        publico_alvo = contexto_estrategico.get('publico_alvo', 'o p√∫blico-alvo')

        prompt = f'''
# INSTRU√á√ÉO PARA IA - ESPECIALISTA EM ESTRAT√âGIA DE NEG√ìCIOS

**TAREFA:** Gerar o conte√∫do para o m√≥dulo "{config['title']}".

**OBJETIVO DO M√ìDULO:** {config['description']}

**CONTEXTO DO PROJETO:**
- **Projeto/Produto:** {tema}
- **Mercado/Nicho:** {segmento}
- **P√∫blico-Alvo Principal:** {publico_alvo}
- **Contexto Estrat√©gico Adicional:** {json.dumps(contexto_estrategico, ensure_ascii=False, indent=2)}

{context_from_previous}

**REGRAS DE GERA√á√ÉO:**
1.  **FOCO ABSOLUTO:** Mantenha-se estritamente no objetivo deste m√≥dulo. N√£o desvie para outros t√≥picos.
2.  **ESTRUTURA:** Organize o conte√∫do de forma clara e l√≥gica, usando Markdown. Comece com um `## Resumo Executivo` e depois desenvolva as se√ß√µes principais.
3.  **PROFUNDIDADE E APLICABILIDADE:** Forne√ßa an√°lises aprofundadas, insights pr√°ticos e recomenda√ß√µes acion√°veis. Evite generalidades.
4.  **LINGUAGEM:** Use uma linguagem profissional, direta e estrat√©gica.
5.  **N√ÉO ALUCINE:** Se alguma informa√ß√£o crucial n√£o estiver dispon√≠vel no contexto fornecido, indique a necessidade de obter essa informa√ß√£o em vez de inventar dados.

**COMECE A GERAR O CONTE√öDO ABAIXO:**

# {config['title']}

## Resumo Executivo

'''
        return prompt

    def _is_ai_refusal(self, content: str) -> bool:
        '''Verifica se a resposta da IA √© uma recusa em gerar o conte√∫do.'''
        if not content or len(content.strip()) < 50:
            return True
        
        refusal_patterns = [
            "n√£o posso criar", "n√£o consigo gerar", "devo recusar", "n√£o sou capaz de", "n√£o posso fornecer", "n√£o posso ajudar com",
            "i'm sorry, but i must decline", "i cannot provide", "i'm unable to", "i can't help with", "i must decline",
            "i cannot assist", "i'm not able to", "i cannot create", "i'm sorry, i cannot", "i cannot generate"
        ]
        
        content_lower = content.lower()
        return any(pattern in content_lower for pattern in refusal_patterns)

    def _generate_fallback_content(self, module_name: str, config: Dict[str, Any], base_data: Dict[str, Any]) -> str:
        '''Gera conte√∫do de fallback robusto quando a IA falha.'''
        context_data = base_data.get('contexto_estrategico', {})
        tema = context_data.get('tema', 'Produto/Servi√ßo')
        segmento = context_data.get('segmento', 'Mercado')
        
        return f'''# {config['title']} (Conte√∫do de Fallback)

## Aviso: Falha na Gera√ß√£o por IA

O conte√∫do a seguir √© um modelo gen√©rico gerado como fallback, pois o sistema de IA n√£o conseguiu produzir uma an√°lise detalhada para este m√≥dulo. Recomenda-se uma an√°lise manual ou uma nova tentativa de gera√ß√£o.

## Resumo Executivo

Este m√≥dulo deveria apresentar estrat√©gias detalhadas para {config['description'].lower()} no segmento de {segmento}. Devido a uma falha na gera√ß√£o, apresentamos uma estrutura padr√£o que deve ser preenchida manualmente.

## Estrutura para An√°lise Manual

### 1. Contexto e Objetivos
- **Segmento de Mercado:** {segmento}
- **Produto/Servi√ßo Foco:** {tema}
- **Objetivo Principal deste M√≥dulo:** Descreva aqui o que se espera alcan√ßar com a an√°lise de '{config['title']}'.

### 2. Pontos-Chave de An√°lise
- **Ponto 1:** Descreva o primeiro aspecto a ser analisado.
- **Ponto 2:** Descreva o segundo aspecto a ser analisado.
- **Ponto 3:** Descreva o terceiro aspecto a ser analisado.

### 3. Estrat√©gias Recomendadas
- **Estrat√©gia A:** Baseado na an√°lise, qual a primeira recomenda√ß√£o?
- **Estrat√©gia B:** Qual a segunda recomenda√ß√£o?

### 4. Plano de Implementa√ß√£o Sugerido
- **Fase 1 (Planejamento):** O que precisa ser feito para preparar a implementa√ß√£o?
- **Fase 2 (Execu√ß√£o):** Quais s√£o os passos pr√°ticos para executar as estrat√©gias?
- **Fase 3 (Otimiza√ß√£o):** Como os resultados ser√£o medidos e o processo otimizado?

### 5. M√©tricas de Sucesso (KPIs)
- **KPI Prim√°rio:** Qual √© o indicador mais importante de sucesso?
- **KPI Secund√°rio:** Que outros indicadores devem ser monitorados?

---
*Gerado pelo ARQV30 Enhanced v3.0 - M√≥dulo de Fallback Robusto*
'''

    async def _generate_consolidated_report(self, session_id: str, results: Dict[str, Any]) -> None:
        '''Gera um relat√≥rio consolidado final com os resumos dos m√≥dulos gerados.'''
        try:
            logger.info("üìã Gerando relat√≥rio consolidado final...")
            modules_dir = BASE_DATA_DIR / session_id / "modules"
            
            consolidated_content = f'''# RELAT√ìRIO FINAL CONSOLIDADO - ARQV30 Enhanced v3.0

**Sess√£o:** {session_id}  
**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}  
**M√≥dulos Gerados:** {results['successful_modules']}/{results['total_modules']}  
**Taxa de Sucesso:** {(results['successful_modules']/results['total_modules']*100):.1f}%

---

## SUM√ÅRIO EXECUTIVO

Este relat√≥rio consolida os {results['successful_modules']} m√≥dulos de an√°lise estrat√©gica gerados para a sess√£o. Cada se√ß√£o abaixo apresenta o resumo executivo do m√≥dulo correspondente.

---

'''

            for module_name in results['modules_generated']:
                config = self.modules_config.get(module_name, {'title': module_name.replace("_", " ").title()})
                file_extension = "json" if module_name == 'cpl_completo' else "md"
                module_file = modules_dir / f"{module_name}.{file_extension}"

                consolidated_content += f"## M√ìDULO: {config['title']}\n\n"

                if module_file.exists():
                    try:
                        with open(module_file, 'r', encoding='utf-8') as f:
                            if file_extension == "json":
                                cpl_data = json.load(f)
                                summary = cpl_data.get('descricao', 'Descri√ß√£o n√£o dispon√≠vel.')
                            else:
                                content = f.read()
                                summary = self._extract_summary(content)
                        consolidated_content += f"{summary}\n\n"
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Erro ao carregar conte√∫do do m√≥dulo {module_name} para relat√≥rio: {e}")
                        consolidated_content += "*Conte√∫do indispon√≠vel devido a um erro de leitura.*\n\n"
                else:
                    consolidated_content += "*Arquivo do m√≥dulo n√£o encontrado.*\n\n"
                consolidated_content += "---\n\n"

            if results['modules_failed']:
                consolidated_content += "\n## M√ìDULOS COM FALHA NA GERA√á√ÉO\n\n"
                for failed in results['modules_failed']:
                    config = self.modules_config.get(failed['module'], {'title': failed['module'].replace("_", " ").title()})
                    consolidated_content += f"- **{config['title']}**: {failed['error']}\n"

            consolidated_path = BASE_DATA_DIR / session_id / "relatorio_final_consolidado.md"
            with open(consolidated_path, 'w', encoding='utf-8') as f:
                f.write(consolidated_content)

            logger.info(f"‚úÖ Relat√≥rio consolidado salvo em: {consolidated_path}")

        except Exception as e:
            logger.error(f"‚ùå Erro cr√≠tico ao gerar o relat√≥rio consolidado: {e}", exc_info=True)
            salvar_erro("geracao_relatorio_consolidado", str(e), contexto={"session_id": session_id})

    # ========================================================================
    # M√âTODOS DE EXPERTISE NO SYNTHESIS ENGINE - IMPLEMENTA√á√ÉO ROBUSTA
    # ========================================================================

    def _update_quality_metrics(self, results: Dict[str, Any], validation: Dict[str, Any]):
        """Atualiza m√©tricas de qualidade dos m√≥dulos"""
        try:
            self.module_quality_metrics['total_generated'] = len(results.get('modules', {}))
            
            # Contar m√≥dulos de alta qualidade
            high_quality_count = 0
            for module_data in results.get('modules', {}).values():
                if isinstance(module_data, dict) and module_data.get('quality_score', 0) > 0.8:
                    high_quality_count += 1
            
            self.module_quality_metrics['high_quality_modules'] = high_quality_count
            self.module_quality_metrics['coherence_score'] = validation.get('coherence_score', 0.0)
            self.module_quality_metrics['synthesis_alignment'] = validation.get('synthesis_alignment', 0.0)
            
            logger.info(f"üìä M√©tricas atualizadas: {high_quality_count}/{self.module_quality_metrics['total_generated']} m√≥dulos de alta qualidade")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao atualizar m√©tricas: {e}")

    async def analyze_synthesis_content_deeply(self, synthesis_data: Dict[str, Any], session_id: str) -> Dict[str, Any]:
        """
        AN√ÅLISE PROFUNDA DO CONTE√öDO DO SYNTHESIS ENGINE
        
        Este m√©todo torna o Module Processor um EXPERT no conte√∫do gerado pelo Synthesis Engine,
        extraindo insights especializados, padr√µes sem√¢nticos e conhecimento espec√≠fico do dom√≠nio.
        
        Args:
            synthesis_data: Dados completos do Synthesis Engine
            session_id: ID da sess√£o
            
        Returns:
            Dict com an√°lise profunda e expertise extra√≠da
        """
        logger.info("üß† INICIANDO AN√ÅLISE PROFUNDA DO SYNTHESIS ENGINE")
        
        try:
            deep_analysis = {
                'session_id': session_id,
                'analysis_timestamp': datetime.now().isoformat(),
                'synthesis_expertise': {},
                'semantic_patterns': {},
                'domain_knowledge': {},
                'content_insights': {},
                'module_generation_strategy': {},
                'quality_indicators': {}
            }
            
            # 1. EXTRA√á√ÉO DE EXPERTISE SEM√ÇNTICA
            logger.info("üîç Extraindo expertise sem√¢ntica...")
            deep_analysis['synthesis_expertise'] = await self._extract_synthesis_expertise(synthesis_data)
            
            # 2. AN√ÅLISE DE PADR√ïES SEM√ÇNTICOS
            logger.info("üß© Analisando padr√µes sem√¢nticos...")
            deep_analysis['semantic_patterns'] = await self._analyze_semantic_patterns(synthesis_data)
            
            # 3. EXTRA√á√ÉO DE CONHECIMENTO DO DOM√çNIO
            logger.info("üìö Extraindo conhecimento do dom√≠nio...")
            deep_analysis['domain_knowledge'] = await self._extract_domain_knowledge(synthesis_data)
            
            # 4. GERA√á√ÉO DE INSIGHTS DE CONTE√öDO
            logger.info("üí° Gerando insights de conte√∫do...")
            deep_analysis['content_insights'] = await self._generate_content_insights(synthesis_data)
            
            # 5. ESTRAT√âGIA DE GERA√á√ÉO DE M√ìDULOS
            logger.info("üéØ Definindo estrat√©gia de gera√ß√£o...")
            deep_analysis['module_generation_strategy'] = await self._define_module_strategy(deep_analysis)
            
            # 6. INDICADORES DE QUALIDADE
            logger.info("üìä Calculando indicadores de qualidade...")
            deep_analysis['quality_indicators'] = await self._calculate_quality_indicators(deep_analysis)
            
            logger.info(f"‚úÖ An√°lise profunda conclu√≠da! Expertise extra√≠da: {len(deep_analysis['synthesis_expertise'])} elementos")
            return deep_analysis
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise profunda: {e}")
            return {'error': str(e), 'session_id': session_id}

    async def _extract_synthesis_expertise(self, synthesis_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extrai expertise espec√≠fica do conte√∫do do Synthesis Engine"""
        try:
            expertise = {
                'key_concepts': [],
                'specialized_terms': [],
                'market_insights': [],
                'strategic_points': [],
                'audience_characteristics': [],
                'competitive_intelligence': [],
                'opportunity_areas': []
            }
            
            # Extrair de diferentes se√ß√µes do synthesis
            synthesis_content = str(synthesis_data)
            
            # 1. Conceitos-chave (usando padr√µes de texto)
            key_concept_patterns = [
                r'conceito[:\s]+([^.]+)',
                r'principal[:\s]+([^.]+)',
                r'fundamental[:\s]+([^.]+)',
                r'essencial[:\s]+([^.]+)'
            ]
            
            for pattern in key_concept_patterns:
                matches = re.findall(pattern, synthesis_content, re.IGNORECASE)
                expertise['key_concepts'].extend([match.strip() for match in matches])
            
            # 2. Termos especializados (palavras t√©cnicas/espec√≠ficas do dom√≠nio)
            specialized_patterns = [
                r'(?:estrat√©gia|t√°tica|abordagem|metodologia|framework)[:\s]+([^.]+)',
                r'(?:segmento|nicho|mercado|p√∫blico)[:\s]+([^.]+)',
                r'(?:tend√™ncia|oportunidade|insight|an√°lise)[:\s]+([^.]+)'
            ]
            
            for pattern in specialized_patterns:
                matches = re.findall(pattern, synthesis_content, re.IGNORECASE)
                expertise['specialized_terms'].extend([match.strip() for match in matches])
            
            # 3. Insights de mercado
            market_patterns = [
                r'mercado[:\s]+([^.]+)',
                r'ind√∫stria[:\s]+([^.]+)',
                r'setor[:\s]+([^.]+)',
                r'economia[:\s]+([^.]+)'
            ]
            
            for pattern in market_patterns:
                matches = re.findall(pattern, synthesis_content, re.IGNORECASE)
                expertise['market_insights'].extend([match.strip() for match in matches])
            
            # 4. Pontos estrat√©gicos
            strategic_patterns = [
                r'estrat√©gia[:\s]+([^.]+)',
                r'objetivo[:\s]+([^.]+)',
                r'meta[:\s]+([^.]+)',
                r'plano[:\s]+([^.]+)'
            ]
            
            for pattern in strategic_patterns:
                matches = re.findall(pattern, synthesis_content, re.IGNORECASE)
                expertise['strategic_points'].extend([match.strip() for match in matches])
            
            # 5. Caracter√≠sticas do p√∫blico
            audience_patterns = [
                r'p√∫blico[:\s]+([^.]+)',
                r'audi√™ncia[:\s]+([^.]+)',
                r'consumidor[:\s]+([^.]+)',
                r'cliente[:\s]+([^.]+)'
            ]
            
            for pattern in audience_patterns:
                matches = re.findall(pattern, synthesis_content, re.IGNORECASE)
                expertise['audience_characteristics'].extend([match.strip() for match in matches])
            
            # Limpar e deduplificar
            for key in expertise:
                if isinstance(expertise[key], list):
                    expertise[key] = list(set([item for item in expertise[key] if len(item) > 5]))[:10]  # Top 10
            
            return expertise
            
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o de expertise: {e}")
            return {}

    async def _analyze_semantic_patterns(self, synthesis_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analisa padr√µes sem√¢nticos no conte√∫do do Synthesis Engine"""
        try:
            patterns = {
                'content_themes': [],
                'recurring_concepts': {},
                'semantic_clusters': [],
                'content_structure': {},
                'narrative_flow': []
            }
            
            synthesis_text = str(synthesis_data)
            
            # 1. Temas de conte√∫do (an√°lise de frequ√™ncia de palavras)
            words = re.findall(r'\b\w{4,}\b', synthesis_text.lower())
            word_freq = {}
            for word in words:
                if word not in ['para', 'com', 'uma', 'dos', 'das', 'que', 'n√£o', 'mais', 'como', 'por']:
                    word_freq[word] = word_freq.get(word, 0) + 1
            
            # Top temas por frequ√™ncia
            patterns['content_themes'] = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:20]
            
            # 2. Conceitos recorrentes
            concept_patterns = [
                'marketing', 'estrat√©gia', 'p√∫blico', 'mercado', 'produto', 'servi√ßo',
                'cliente', 'consumidor', 'an√°lise', 'oportunidade', 'tend√™ncia',
                'segmento', 'nicho', 'competi√ß√£o', 'vantagem', 'posicionamento'
            ]
            
            for concept in concept_patterns:
                count = synthesis_text.lower().count(concept)
                if count > 0:
                    patterns['recurring_concepts'][concept] = count
            
            # 3. Estrutura do conte√∫do
            sections = synthesis_text.split('\n\n')
            patterns['content_structure'] = {
                'total_sections': len(sections),
                'avg_section_length': sum(len(s) for s in sections) / len(sections) if sections else 0,
                'section_types': self._classify_sections(sections)
            }
            
            return patterns
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise sem√¢ntica: {e}")
            return {}

    async def _extract_domain_knowledge(self, synthesis_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extrai conhecimento espec√≠fico do dom√≠nio"""
        try:
            domain_knowledge = {
                'industry_specifics': [],
                'technical_concepts': [],
                'business_models': [],
                'market_dynamics': [],
                'success_factors': [],
                'risk_factors': [],
                'best_practices': []
            }
            
            synthesis_text = str(synthesis_data)
            
            # 1. Especificidades da ind√∫stria
            industry_patterns = [
                r'(?:ind√∫stria|setor|mercado)\s+(?:de\s+)?([^.]+?)(?:\s+(?:√©|tem|possui|apresenta))',
                r'(?:no\s+)?(?:ramo|segmento|√°rea)\s+(?:de\s+)?([^.]+?)(?:\s+(?:√©|tem|possui))'
            ]
            
            for pattern in industry_patterns:
                matches = re.findall(pattern, synthesis_text, re.IGNORECASE)
                domain_knowledge['industry_specifics'].extend([match.strip() for match in matches])
            
            # 2. Conceitos t√©cnicos
            technical_patterns = [
                r'(?:tecnologia|ferramenta|plataforma|sistema)\s+([^.]+)',
                r'(?:m√©todo|processo|procedimento|t√©cnica)\s+([^.]+)',
                r'(?:algoritmo|modelo|framework|arquitetura)\s+([^.]+)'
            ]
            
            for pattern in technical_patterns:
                matches = re.findall(pattern, synthesis_text, re.IGNORECASE)
                domain_knowledge['technical_concepts'].extend([match.strip() for match in matches])
            
            # 3. Modelos de neg√≥cio
            business_patterns = [
                r'(?:modelo|estrat√©gia|abordagem)\s+(?:de\s+)?(?:neg√≥cio|comercial|empresarial)\s+([^.]+)',
                r'(?:receita|monetiza√ß√£o|faturamento)\s+([^.]+)',
                r'(?:canal|distribui√ß√£o|vendas)\s+([^.]+)'
            ]
            
            for pattern in business_patterns:
                matches = re.findall(pattern, synthesis_text, re.IGNORECASE)
                domain_knowledge['business_models'].extend([match.strip() for match in matches])
            
            # 4. Din√¢micas de mercado
            market_patterns = [
                r'(?:tend√™ncia|movimento|dire√ß√£o)\s+(?:do\s+)?mercado\s+([^.]+)',
                r'(?:crescimento|expans√£o|desenvolvimento)\s+([^.]+)',
                r'(?:demanda|procura|interesse)\s+([^.]+)'
            ]
            
            for pattern in market_patterns:
                matches = re.findall(pattern, synthesis_text, re.IGNORECASE)
                domain_knowledge['market_dynamics'].extend([match.strip() for match in matches])
            
            # Limpar e deduplificar
            for key in domain_knowledge:
                if isinstance(domain_knowledge[key], list):
                    domain_knowledge[key] = list(set([item for item in domain_knowledge[key] if len(item) > 3]))[:8]
            
            return domain_knowledge
            
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o de conhecimento: {e}")
            return {}

    async def _generate_content_insights(self, synthesis_data: Dict[str, Any]) -> Dict[str, Any]:
        """Gera insights espec√≠ficos do conte√∫do para orientar a gera√ß√£o de m√≥dulos"""
        try:
            insights = {
                'content_quality_score': 0.0,
                'depth_indicators': {},
                'specialization_level': '',
                'content_gaps': [],
                'enhancement_opportunities': [],
                'module_priorities': [],
                'coherence_factors': {}
            }
            
            synthesis_text = str(synthesis_data)
            
            # 1. Score de qualidade do conte√∫do
            quality_factors = {
                'length': min(len(synthesis_text) / 10000, 1.0),  # Normalizado para 10k chars
                'complexity': len(set(synthesis_text.split())) / len(synthesis_text.split()) if synthesis_text.split() else 0,
                'structure': synthesis_text.count('\n') / 100,  # Indicador de estrutura√ß√£o
                'specificity': len(re.findall(r'\d+', synthesis_text)) / 100  # Presen√ßa de dados espec√≠ficos
            }
            
            insights['content_quality_score'] = sum(quality_factors.values()) / len(quality_factors)
            
            # 2. Indicadores de profundidade
            insights['depth_indicators'] = {
                'detailed_analysis': synthesis_text.lower().count('an√°lise') + synthesis_text.lower().count('estudo'),
                'data_references': len(re.findall(r'\d+%|\d+\.\d+%|\d+,\d+%', synthesis_text)),
                'expert_terminology': len(re.findall(r'(?:estrat√©gia|metodologia|framework|abordagem)', synthesis_text, re.IGNORECASE)),
                'case_studies': synthesis_text.lower().count('caso') + synthesis_text.lower().count('exemplo')
            }
            
            # 3. N√≠vel de especializa√ß√£o
            specialization_score = sum(insights['depth_indicators'].values())
            if specialization_score > 50:
                insights['specialization_level'] = 'expert'
            elif specialization_score > 20:
                insights['specialization_level'] = 'advanced'
            elif specialization_score > 10:
                insights['specialization_level'] = 'intermediate'
            else:
                insights['specialization_level'] = 'basic'
            
            # 4. Lacunas de conte√∫do (√°reas que podem precisar de mais desenvolvimento)
            expected_topics = [
                'p√∫blico-alvo', 'concorr√™ncia', 'mercado', 'estrat√©gia', 'produto',
                'pre√ßo', 'distribui√ß√£o', 'comunica√ß√£o', 'm√©tricas', 'cronograma'
            ]
            
            for topic in expected_topics:
                if topic.lower() not in synthesis_text.lower():
                    insights['content_gaps'].append(topic)
            
            # 5. Oportunidades de aprimoramento
            if insights['content_quality_score'] < 0.7:
                insights['enhancement_opportunities'].append('Expandir an√°lise com mais detalhes espec√≠ficos')
            if len(insights['content_gaps']) > 3:
                insights['enhancement_opportunities'].append('Abordar t√≥picos essenciais ausentes')
            if insights['depth_indicators']['data_references'] < 5:
                insights['enhancement_opportunities'].append('Incluir mais dados quantitativos')
            
            return insights
            
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o de insights: {e}")
            return {}

    async def _define_module_strategy(self, deep_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Define estrat√©gia de gera√ß√£o de m√≥dulos baseada na an√°lise profunda"""
        try:
            strategy = {
                'generation_approach': '',
                'priority_modules': [],
                'content_adaptation': {},
                'quality_targets': {},
                'coherence_strategy': {},
                'specialization_focus': []
            }
            
            # 1. Abordagem de gera√ß√£o baseada no n√≠vel de especializa√ß√£o
            specialization = deep_analysis.get('content_insights', {}).get('specialization_level', 'basic')
            
            if specialization == 'expert':
                strategy['generation_approach'] = 'deep_specialization'
                strategy['quality_targets']['min_quality_score'] = 0.9
            elif specialization == 'advanced':
                strategy['generation_approach'] = 'enhanced_analysis'
                strategy['quality_targets']['min_quality_score'] = 0.8
            else:
                strategy['generation_approach'] = 'comprehensive_coverage'
                strategy['quality_targets']['min_quality_score'] = 0.7
            
            # 2. M√≥dulos priorit√°rios baseados no conte√∫do
            expertise = deep_analysis.get('synthesis_expertise', {})
            
            if expertise.get('market_insights'):
                strategy['priority_modules'].append('insights_mercado')
            if expertise.get('audience_characteristics'):
                strategy['priority_modules'].append('avatares')
            if expertise.get('competitive_intelligence'):
                strategy['priority_modules'].append('analise_competitiva')
            if expertise.get('strategic_points'):
                strategy['priority_modules'].append('estrategia_posicionamento')
            
            # 3. Adapta√ß√£o de conte√∫do
            semantic_patterns = deep_analysis.get('semantic_patterns', {})
            recurring_concepts = semantic_patterns.get('recurring_concepts', {})
            
            strategy['content_adaptation'] = {
                'emphasize_concepts': list(recurring_concepts.keys())[:5],
                'content_style': 'data_driven' if recurring_concepts.get('an√°lise', 0) > 5 else 'strategic',
                'detail_level': 'high' if specialization in ['expert', 'advanced'] else 'medium'
            }
            
            # 4. Estrat√©gia de coer√™ncia
            strategy['coherence_strategy'] = {
                'cross_reference_modules': True,
                'maintain_terminology': True,
                'align_recommendations': True,
                'consistent_tone': True
            }
            
            # 5. Foco de especializa√ß√£o
            domain_knowledge = deep_analysis.get('domain_knowledge', {})
            if domain_knowledge.get('industry_specifics'):
                strategy['specialization_focus'].append('industry_expertise')
            if domain_knowledge.get('technical_concepts'):
                strategy['specialization_focus'].append('technical_depth')
            if domain_knowledge.get('business_models'):
                strategy['specialization_focus'].append('business_strategy')
            
            return strategy
            
        except Exception as e:
            logger.error(f"‚ùå Erro na defini√ß√£o de estrat√©gia: {e}")
            return {}

    async def _calculate_quality_indicators(self, deep_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Calcula indicadores de qualidade para orientar a gera√ß√£o"""
        try:
            indicators = {
                'content_richness': 0.0,
                'semantic_coherence': 0.0,
                'domain_expertise': 0.0,
                'strategic_alignment': 0.0,
                'overall_readiness': 0.0,
                'recommendations': []
            }
            
            # 1. Riqueza de conte√∫do
            content_insights = deep_analysis.get('content_insights', {})
            indicators['content_richness'] = content_insights.get('content_quality_score', 0.0)
            
            # 2. Coer√™ncia sem√¢ntica
            semantic_patterns = deep_analysis.get('semantic_patterns', {})
            recurring_concepts = semantic_patterns.get('recurring_concepts', {})
            if recurring_concepts:
                # Mais conceitos recorrentes = maior coer√™ncia
                indicators['semantic_coherence'] = min(len(recurring_concepts) / 10, 1.0)
            
            # 3. Expertise do dom√≠nio
            domain_knowledge = deep_analysis.get('domain_knowledge', {})
            domain_elements = sum(len(v) if isinstance(v, list) else 0 for v in domain_knowledge.values())
            indicators['domain_expertise'] = min(domain_elements / 20, 1.0)
            
            # 4. Alinhamento estrat√©gico
            synthesis_expertise = deep_analysis.get('synthesis_expertise', {})
            strategic_elements = len(synthesis_expertise.get('strategic_points', []))
            indicators['strategic_alignment'] = min(strategic_elements / 5, 1.0)
            
            # 5. Prontid√£o geral
            indicators['overall_readiness'] = (
                indicators['content_richness'] * 0.3 +
                indicators['semantic_coherence'] * 0.25 +
                indicators['domain_expertise'] * 0.25 +
                indicators['strategic_alignment'] * 0.2
            )
            
            # 6. Recomenda√ß√µes baseadas nos indicadores
            if indicators['content_richness'] < 0.6:
                indicators['recommendations'].append('Enriquecer conte√∫do com mais detalhes espec√≠ficos')
            if indicators['semantic_coherence'] < 0.5:
                indicators['recommendations'].append('Melhorar consist√™ncia terminol√≥gica')
            if indicators['domain_expertise'] < 0.6:
                indicators['recommendations'].append('Aprofundar conhecimento espec√≠fico do dom√≠nio')
            if indicators['strategic_alignment'] < 0.7:
                indicators['recommendations'].append('Fortalecer elementos estrat√©gicos')
            
            if indicators['overall_readiness'] > 0.8:
                indicators['recommendations'].append('‚úÖ Conte√∫do pronto para gera√ß√£o de m√≥dulos de alta qualidade')
            
            return indicators
            
        except Exception as e:
            logger.error(f"‚ùå Erro no c√°lculo de indicadores: {e}")
            return {}

    def _classify_sections(self, sections: List[str]) -> Dict[str, int]:
        """Classifica se√ß√µes do conte√∫do por tipo"""
        try:
            section_types = {
                'analytical': 0,
                'strategic': 0,
                'descriptive': 0,
                'data_driven': 0,
                'recommendations': 0
            }
            
            for section in sections:
                section_lower = section.lower()
                
                if any(word in section_lower for word in ['an√°lise', 'estudo', 'pesquisa', 'investiga√ß√£o']):
                    section_types['analytical'] += 1
                elif any(word in section_lower for word in ['estrat√©gia', 'plano', 'objetivo', 'meta']):
                    section_types['strategic'] += 1
                elif any(word in section_lower for word in ['recomenda√ß√£o', 'sugest√£o', 'proposta', 'a√ß√£o']):
                    section_types['recommendations'] += 1
                elif re.search(r'\d+%|\d+\.\d+|\d+,\d+', section):
                    section_types['data_driven'] += 1
                else:
                    section_types['descriptive'] += 1
            
            return section_types
            
        except Exception as e:
            logger.error(f"‚ùå Erro na classifica√ß√£o de se√ß√µes: {e}")
            return {}

    async def generate_expert_modules_from_synthesis(self, session_id: str, synthesis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        GERA√á√ÉO DE M√ìDULOS EXPERT BASEADA NA AN√ÅLISE PROFUNDA DO SYNTHESIS ENGINE
        
        Este √© o m√©todo PRINCIPAL que utiliza toda a expertise extra√≠da do Synthesis Engine
        para gerar m√≥dulos altamente coerentes e especializados.
        """
        logger.info("üéì INICIANDO GERA√á√ÉO EXPERT DE M√ìDULOS COM BASE NO SYNTHESIS ENGINE")
        
        try:
            # 1. AN√ÅLISE PROFUNDA DO SYNTHESIS ENGINE
            logger.info("üß† Executando an√°lise profunda do Synthesis Engine...")
            deep_analysis = await self.analyze_synthesis_content_deeply(synthesis_data, session_id)
            
            if deep_analysis.get('error'):
                return self._create_error_result(session_id, f"Erro na an√°lise profunda: {deep_analysis['error']}")
            
            # 2. PREPARA√á√ÉO DO CONTEXTO EXPERT
            logger.info("üéØ Preparando contexto expert para gera√ß√£o...")
            expert_context = await self._prepare_expert_context(synthesis_data, deep_analysis)
            
            # 3. GERA√á√ÉO SEQUENCIAL COM EXPERTISE
            logger.info("‚öôÔ∏è Gerando m√≥dulos com expertise especializada...")
            expert_results = await self._generate_modules_with_expertise(session_id, expert_context, deep_analysis)
            
            # 4. VALIDA√á√ÉO DE COER√äNCIA EXPERT
            logger.info("üîç Validando coer√™ncia expert entre m√≥dulos...")
            expert_validation = await self._validate_expert_coherence(session_id, expert_results, deep_analysis)
            
            # 5. REFINAMENTO BASEADO NA EXPERTISE
            if expert_validation.get('needs_expert_refinement'):
                logger.info("üîß Refinando m√≥dulos com base na expertise...")
                expert_results = await self._refine_modules_with_expertise(session_id, expert_results, expert_validation, deep_analysis)
            
            # 6. M√âTRICAS FINAIS DE EXPERTISE
            final_metrics = await self._calculate_expert_metrics(expert_results, deep_analysis, expert_validation)
            
            logger.info(f"üéâ GERA√á√ÉO EXPERT CONCLU√çDA! Score de expertise: {final_metrics.get('expertise_score', 0):.2f}")
            
            return {
                **expert_results,
                'synthesis_expertise_applied': True,
                'deep_analysis': deep_analysis,
                'expert_validation': expert_validation,
                'expert_metrics': final_metrics,
                'generation_approach': 'synthesis_expert'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o expert: {e}")
            return self._create_error_result(session_id, str(e))

    async def _prepare_expert_context(self, synthesis_data: Dict[str, Any], deep_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Prepara contexto expert enriquecido com a an√°lise profunda"""
        try:
            expert_context = {
                'original_synthesis': synthesis_data,
                'extracted_expertise': deep_analysis.get('synthesis_expertise', {}),
                'semantic_intelligence': deep_analysis.get('semantic_patterns', {}),
                'domain_mastery': deep_analysis.get('domain_knowledge', {}),
                'content_insights': deep_analysis.get('content_insights', {}),
                'generation_strategy': deep_analysis.get('module_generation_strategy', {}),
                'quality_benchmarks': deep_analysis.get('quality_indicators', {}),
                'expert_prompts': await self._create_expert_prompts(deep_analysis)
            }
            
            return expert_context
            
        except Exception as e:
            logger.error(f"‚ùå Erro na prepara√ß√£o do contexto expert: {e}")
            return {}

    async def _create_expert_prompts(self, deep_analysis: Dict[str, Any]) -> Dict[str, str]:
        """Cria prompts especializados baseados na an√°lise profunda"""
        try:
            expertise = deep_analysis.get('synthesis_expertise', {})
            strategy = deep_analysis.get('module_generation_strategy', {})
            
            expert_prompts = {
                'expert_prefix': f"""
# VOC√ä √â UM CONSULTOR EXPERT ESPECIALIZADO

Baseado na an√°lise profunda do Synthesis Engine, voc√™ domina:

**CONCEITOS-CHAVE IDENTIFICADOS:**
{', '.join(expertise.get('key_concepts', [])[:5])}

**TERMOS ESPECIALIZADOS:**
{', '.join(expertise.get('specialized_terms', [])[:5])}

**INSIGHTS DE MERCADO:**
{', '.join(expertise.get('market_insights', [])[:3])}

**ABORDAGEM DE GERA√á√ÉO:** {strategy.get('generation_approach', 'comprehensive')}
**N√çVEL DE ESPECIALIZA√á√ÉO:** {deep_analysis.get('content_insights', {}).get('specialization_level', 'intermediate')}

INSTRU√á√ïES CR√çTICAS:
- Use EXATAMENTE os termos e conceitos identificados na an√°lise
- Mantenha COER√äNCIA total com o Synthesis Engine
- Aplique o n√≠vel de especializa√ß√£o apropriado
- Gere conte√∫do EXPERT baseado no conhecimento extra√≠do
""",
                
                'coherence_instruction': """
MANTER COER√äNCIA ABSOLUTA:
- Referencie conceitos do Synthesis Engine
- Use terminologia consistente
- Alinhe recomenda√ß√µes com insights identificados
- Mantenha tom e estilo consistentes
""",
                
                'quality_standard': f"""
PADR√ÉO DE QUALIDADE EXPERT:
- Score m√≠nimo: {strategy.get('quality_targets', {}).get('min_quality_score', 0.8)}
- Profundidade: {strategy.get('content_adaptation', {}).get('detail_level', 'high')}
- Estilo: {strategy.get('content_adaptation', {}).get('content_style', 'strategic')}
"""
            }
            
            return expert_prompts
            
        except Exception as e:
            logger.error(f"‚ùå Erro na cria√ß√£o de prompts expert: {e}")
            return {}

    async def _generate_modules_with_expertise(self, session_id: str, expert_context: Dict[str, Any], deep_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Gera m√≥dulos aplicando toda a expertise extra√≠da"""
        try:
            results = {
                'session_id': session_id,
                'modules': {},
                'failed_modules': [],
                'expert_applied': True,
                'generation_stats': {
                    'total_attempted': 0,
                    'successful': 0,
                    'expert_quality': 0,
                    'synthesis_alignment': 0.0
                }
            }
            
            # Obter estrat√©gia de gera√ß√£o
            strategy = deep_analysis.get('module_generation_strategy', {})
            priority_modules = strategy.get('priority_modules', [])
            
            # Gerar m√≥dulos priorit√°rios primeiro
            all_modules = list(self.modules_config.keys())
            ordered_modules = priority_modules + [m for m in all_modules if m not in priority_modules]
            
            for module_name in ordered_modules:
                try:
                    logger.info(f"üéØ Gerando m√≥dulo expert: {module_name}")
                    
                    # Aplicar expertise espec√≠fica para o m√≥dulo
                    module_result = await self._generate_single_expert_module(
                        module_name, expert_context, deep_analysis, session_id
                    )
                    
                    if module_result.get('success'):
                        results['modules'][module_name] = module_result
                        results['generation_stats']['successful'] += 1
                        
                        # Verificar qualidade expert
                        if module_result.get('expert_quality_score', 0) > 0.8:
                            results['generation_stats']['expert_quality'] += 1
                    else:
                        results['failed_modules'].append({
                            'module': module_name,
                            'error': module_result.get('error', 'Unknown error')
                        })
                    
                    results['generation_stats']['total_attempted'] += 1
                    
                except Exception as e:
                    logger.error(f"‚ùå Erro no m√≥dulo {module_name}: {e}")
                    results['failed_modules'].append({
                        'module': module_name,
                        'error': str(e)
                    })
            
            # Calcular alinhamento com synthesis
            if results['generation_stats']['successful'] > 0:
                results['generation_stats']['synthesis_alignment'] = (
                    results['generation_stats']['expert_quality'] / 
                    results['generation_stats']['successful']
                )
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o com expertise: {e}")
            return {'error': str(e), 'session_id': session_id}

    async def _generate_single_expert_module(self, module_name: str, expert_context: Dict[str, Any], deep_analysis: Dict[str, Any], session_id: str) -> Dict[str, Any]:
        """Gera um √∫nico m√≥dulo com aplica√ß√£o de expertise"""
        try:
            module_config = self.modules_config.get(module_name, {})
            expert_prompts = expert_context.get('expert_prompts', {})
            
            # Construir prompt expert para o m√≥dulo
            expert_prompt = f"""
{expert_prompts.get('expert_prefix', '')}

# M√ìDULO: {module_config.get('title', module_name)}

{module_config.get('description', '')}

{expert_prompts.get('coherence_instruction', '')}

{expert_prompts.get('quality_standard', '')}

## CONTEXTO EXPERT ESPEC√çFICO:

**EXPERTISE APLIC√ÅVEL:**
{self._get_relevant_expertise_for_module(module_name, expert_context)}

**CONHECIMENTO DO DOM√çNIO:**
{self._get_relevant_domain_knowledge_for_module(module_name, expert_context)}

**INSIGHTS DE CONTE√öDO:**
{self._get_relevant_insights_for_module(module_name, expert_context)}

## DADOS DO SYNTHESIS ENGINE:
{str(expert_context.get('original_synthesis', {}))[:2000]}...

GERE O M√ìDULO COM EXPERTISE M√ÅXIMA E COER√äNCIA TOTAL!
"""
            
            # Gerar conte√∫do com IA
            if self.ai_manager:
                content = await self.ai_manager.generate_content(
                    prompt=expert_prompt,
                    max_tokens=3000,
                    temperature=0.7
                )
                
                # Calcular score de qualidade expert
                expert_quality_score = await self._calculate_module_expert_score(
                    content, expert_context, module_name
                )
                
                return {
                    'success': True,
                    'content': content,
                    'expert_quality_score': expert_quality_score,
                    'module_name': module_name,
                    'expertise_applied': True,
                    'generation_timestamp': datetime.now().isoformat()
                }
            else:
                return {
                    'success': False,
                    'error': 'AI Manager n√£o dispon√≠vel',
                    'module_name': module_name
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o do m√≥dulo expert {module_name}: {e}")
            return {
                'success': False,
                'error': str(e),
                'module_name': module_name
            }

    def _get_relevant_expertise_for_module(self, module_name: str, expert_context: Dict[str, Any]) -> str:
        """Obt√©m expertise relevante para um m√≥dulo espec√≠fico"""
        try:
            expertise = expert_context.get('extracted_expertise', {})
            
            # Mapear m√≥dulos para tipos de expertise
            module_expertise_map = {
                'avatares': expertise.get('audience_characteristics', []),
                'analise_competitiva': expertise.get('competitive_intelligence', []),
                'insights_mercado': expertise.get('market_insights', []),
                'estrategia_posicionamento': expertise.get('strategic_points', []),
                'sintese_master': expertise.get('key_concepts', [])
            }
            
            relevant_expertise = module_expertise_map.get(module_name, expertise.get('key_concepts', []))
            return ' | '.join(relevant_expertise[:5]) if relevant_expertise else 'Expertise geral aplic√°vel'
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter expertise para {module_name}: {e}")
            return 'Expertise n√£o dispon√≠vel'

    def _get_relevant_domain_knowledge_for_module(self, module_name: str, expert_context: Dict[str, Any]) -> str:
        """Obt√©m conhecimento do dom√≠nio relevante para um m√≥dulo espec√≠fico"""
        try:
            domain_knowledge = expert_context.get('domain_mastery', {})
            
            # Mapear m√≥dulos para conhecimento do dom√≠nio
            module_domain_map = {
                'analise_competitiva': domain_knowledge.get('market_dynamics', []),
                'insights_mercado': domain_knowledge.get('industry_specifics', []),
                'estrategia_posicionamento': domain_knowledge.get('business_models', []),
                'plano_marketing': domain_knowledge.get('best_practices', [])
            }
            
            relevant_knowledge = module_domain_map.get(module_name, domain_knowledge.get('industry_specifics', []))
            return ' | '.join(relevant_knowledge[:3]) if relevant_knowledge else 'Conhecimento geral do dom√≠nio'
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter conhecimento para {module_name}: {e}")
            return 'Conhecimento n√£o dispon√≠vel'

    def _get_relevant_insights_for_module(self, module_name: str, expert_context: Dict[str, Any]) -> str:
        """Obt√©m insights relevantes para um m√≥dulo espec√≠fico"""
        try:
            content_insights = expert_context.get('content_insights', {})
            
            insights_summary = f"""
N√≠vel de especializa√ß√£o: {content_insights.get('specialization_level', 'intermediate')}
Score de qualidade: {content_insights.get('content_quality_score', 0):.2f}
Oportunidades: {', '.join(content_insights.get('enhancement_opportunities', [])[:2])}
"""
            return insights_summary
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter insights para {module_name}: {e}")
            return 'Insights n√£o dispon√≠veis'

    async def _calculate_module_expert_score(self, content: str, expert_context: Dict[str, Any], module_name: str) -> float:
        """Calcula score de qualidade expert para um m√≥dulo"""
        try:
            score = 0.0
            
            # 1. Uso de expertise extra√≠da (30%)
            expertise = expert_context.get('extracted_expertise', {})
            all_expertise_terms = []
            for expertise_list in expertise.values():
                if isinstance(expertise_list, list):
                    all_expertise_terms.extend(expertise_list)
            
            expertise_usage = sum(1 for term in all_expertise_terms if term.lower() in content.lower())
            expertise_score = min(expertise_usage / 5, 1.0) * 0.3
            
            # 2. Coer√™ncia sem√¢ntica (25%)
            semantic_patterns = expert_context.get('semantic_intelligence', {})
            recurring_concepts = semantic_patterns.get('recurring_concepts', {})
            
            concept_usage = sum(1 for concept in recurring_concepts.keys() if concept in content.lower())
            semantic_score = min(concept_usage / 3, 1.0) * 0.25
            
            # 3. Aplica√ß√£o de conhecimento do dom√≠nio (25%)
            domain_knowledge = expert_context.get('domain_mastery', {})
            all_domain_terms = []
            for domain_list in domain_knowledge.values():
                if isinstance(domain_list, list):
                    all_domain_terms.extend(domain_list)
            
            domain_usage = sum(1 for term in all_domain_terms if term.lower() in content.lower())
            domain_score = min(domain_usage / 3, 1.0) * 0.25
            
            # 4. Qualidade geral do conte√∫do (20%)
            content_quality = min(len(content) / 2000, 1.0) * 0.2  # Normalizado para 2k chars
            
            score = expertise_score + semantic_score + domain_score + content_quality
            
            return min(score, 1.0)
            
        except Exception as e:
            logger.error(f"‚ùå Erro no c√°lculo do score expert: {e}")
            return 0.0

    async def _validate_expert_coherence(self, session_id: str, expert_results: Dict[str, Any], deep_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Valida coer√™ncia expert entre m√≥dulos"""
        try:
            validation = {
                'coherence_score': 0.0,
                'synthesis_alignment': 0.0,
                'expert_consistency': 0.0,
                'needs_expert_refinement': False,
                'refinement_areas': [],
                'quality_distribution': {}
            }
            
            modules = expert_results.get('modules', {})
            if not modules:
                return validation
            
            # 1. Score de coer√™ncia entre m√≥dulos
            module_contents = [m.get('content', '') for m in modules.values() if m.get('content')]
            
            if len(module_contents) > 1:
                # Verificar consist√™ncia terminol√≥gica
                expertise = deep_analysis.get('synthesis_expertise', {})
                key_terms = expertise.get('key_concepts', [])[:5]
                
                term_consistency = []
                for term in key_terms:
                    usage_count = sum(1 for content in module_contents if term.lower() in content.lower())
                    consistency = usage_count / len(module_contents)
                    term_consistency.append(consistency)
                
                validation['expert_consistency'] = sum(term_consistency) / len(term_consistency) if term_consistency else 0.0
            
            # 2. Alinhamento com synthesis
            original_synthesis = str(deep_analysis.get('original_synthesis', ''))
            synthesis_terms = set(original_synthesis.lower().split())
            
            alignment_scores = []
            for content in module_contents:
                content_terms = set(content.lower().split())
                common_terms = synthesis_terms.intersection(content_terms)
                alignment = len(common_terms) / len(synthesis_terms) if synthesis_terms else 0
                alignment_scores.append(alignment)
            
            validation['synthesis_alignment'] = sum(alignment_scores) / len(alignment_scores) if alignment_scores else 0.0
            
            # 3. Score geral de coer√™ncia
            validation['coherence_score'] = (
                validation['expert_consistency'] * 0.6 +
                validation['synthesis_alignment'] * 0.4
            )
            
            # 4. Distribui√ß√£o de qualidade
            quality_scores = [m.get('expert_quality_score', 0) for m in modules.values()]
            validation['quality_distribution'] = {
                'high_quality': len([s for s in quality_scores if s > 0.8]),
                'medium_quality': len([s for s in quality_scores if 0.6 <= s <= 0.8]),
                'low_quality': len([s for s in quality_scores if s < 0.6]),
                'average_score': sum(quality_scores) / len(quality_scores) if quality_scores else 0.0
            }
            
            # 5. Necessidade de refinamento
            if validation['coherence_score'] < 0.7:
                validation['needs_expert_refinement'] = True
                validation['refinement_areas'].append('Melhorar consist√™ncia terminol√≥gica')
            
            if validation['synthesis_alignment'] < 0.6:
                validation['needs_expert_refinement'] = True
                validation['refinement_areas'].append('Aumentar alinhamento com synthesis')
            
            if validation['quality_distribution']['low_quality'] > len(modules) * 0.3:
                validation['needs_expert_refinement'] = True
                validation['refinement_areas'].append('Elevar qualidade dos m√≥dulos de baixo score')
            
            return validation
            
        except Exception as e:
            logger.error(f"‚ùå Erro na valida√ß√£o expert: {e}")
            return {'error': str(e)}

    async def _refine_modules_with_expertise(self, session_id: str, expert_results: Dict[str, Any], validation: Dict[str, Any], deep_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Refina m√≥dulos aplicando expertise adicional"""
        try:
            logger.info("üîß Iniciando refinamento expert dos m√≥dulos...")
            
            refinement_areas = validation.get('refinement_areas', [])
            modules = expert_results.get('modules', {})
            
            for module_name, module_data in modules.items():
                try:
                    current_score = module_data.get('expert_quality_score', 0)
                    
                    # Refinar apenas m√≥dulos que precisam
                    if current_score < 0.8:
                        logger.info(f"üîß Refinando m√≥dulo: {module_name}")
                        
                        refined_content = await self._apply_expert_refinement(
                            module_name, module_data.get('content', ''), 
                            refinement_areas, deep_analysis
                        )
                        
                        if refined_content:
                            # Atualizar m√≥dulo com conte√∫do refinado
                            modules[module_name]['content'] = refined_content
                            modules[module_name]['refined'] = True
                            modules[module_name]['refinement_timestamp'] = datetime.now().isoformat()
                            
                            # Recalcular score
                            expert_context = {
                                'extracted_expertise': deep_analysis.get('synthesis_expertise', {}),
                                'semantic_intelligence': deep_analysis.get('semantic_patterns', {}),
                                'domain_mastery': deep_analysis.get('domain_knowledge', {})
                            }
                            
                            new_score = await self._calculate_module_expert_score(
                                refined_content, expert_context, module_name
                            )
                            modules[module_name]['expert_quality_score'] = new_score
                            
                            logger.info(f"‚úÖ M√≥dulo {module_name} refinado: {current_score:.2f} ‚Üí {new_score:.2f}")
                
                except Exception as e:
                    logger.error(f"‚ùå Erro no refinamento do m√≥dulo {module_name}: {e}")
            
            expert_results['modules'] = modules
            expert_results['refinement_applied'] = True
            
            return expert_results
            
        except Exception as e:
            logger.error(f"‚ùå Erro no refinamento expert: {e}")
            return expert_results

    async def _apply_expert_refinement(self, module_name: str, original_content: str, refinement_areas: List[str], deep_analysis: Dict[str, Any]) -> str:
        """Aplica refinamento expert a um m√≥dulo espec√≠fico"""
        try:
            expertise = deep_analysis.get('synthesis_expertise', {})
            
            refinement_prompt = f"""
# REFINAMENTO EXPERT DO M√ìDULO: {module_name}

## CONTE√öDO ORIGINAL:
{original_content}

## √ÅREAS DE REFINAMENTO NECESS√ÅRIAS:
{chr(10).join(f'- {area}' for area in refinement_areas)}

## EXPERTISE A SER APLICADA:
**Conceitos-chave:** {', '.join(expertise.get('key_concepts', [])[:5])}
**Termos especializados:** {', '.join(expertise.get('specialized_terms', [])[:5])}
**Insights de mercado:** {', '.join(expertise.get('market_insights', [])[:3])}

## INSTRU√á√ïES DE REFINAMENTO:
1. MANTER todo o conte√∫do original v√°lido
2. ADICIONAR os conceitos e termos especializados identificados
3. MELHORAR a coer√™ncia com o Synthesis Engine
4. ELEVAR o n√≠vel de especializa√ß√£o
5. GARANTIR consist√™ncia terminol√≥gica

REFINE O CONTE√öDO APLICANDO M√ÅXIMA EXPERTISE:
"""
            
            if self.ai_manager:
                refined_content = await self.ai_manager.generate_content(
                    prompt=refinement_prompt,
                    max_tokens=3500,
                    temperature=0.5
                )
                return refined_content
            else:
                return original_content
                
        except Exception as e:
            logger.error(f"‚ùå Erro no refinamento do m√≥dulo {module_name}: {e}")
            return original_content

    async def _calculate_expert_metrics(self, expert_results: Dict[str, Any], deep_analysis: Dict[str, Any], validation: Dict[str, Any]) -> Dict[str, Any]:
        """Calcula m√©tricas finais de expertise"""
        try:
            metrics = {
                'expertise_score': 0.0,
                'synthesis_integration_score': 0.0,
                'module_quality_average': 0.0,
                'coherence_achievement': 0.0,
                'expert_features_applied': 0,
                'overall_expert_rating': '',
                'recommendations': []
            }
            
            modules = expert_results.get('modules', {})
            
            # 1. Score m√©dio de qualidade dos m√≥dulos
            quality_scores = [m.get('expert_quality_score', 0) for m in modules.values()]
            metrics['module_quality_average'] = sum(quality_scores) / len(quality_scores) if quality_scores else 0.0
            
            # 2. Score de integra√ß√£o com synthesis
            metrics['synthesis_integration_score'] = validation.get('synthesis_alignment', 0.0)
            
            # 3. Achievement de coer√™ncia
            metrics['coherence_achievement'] = validation.get('coherence_score', 0.0)
            
            # 4. Features expert aplicadas
            expert_features = 0
            if deep_analysis.get('synthesis_expertise'):
                expert_features += 1
            if deep_analysis.get('semantic_patterns'):
                expert_features += 1
            if deep_analysis.get('domain_knowledge'):
                expert_features += 1
            if deep_analysis.get('content_insights'):
                expert_features += 1
            
            metrics['expert_features_applied'] = expert_features
            
            # 5. Score geral de expertise
            metrics['expertise_score'] = (
                metrics['module_quality_average'] * 0.4 +
                metrics['synthesis_integration_score'] * 0.3 +
                metrics['coherence_achievement'] * 0.2 +
                (expert_features / 4) * 0.1
            )
            
            # 6. Rating geral
            if metrics['expertise_score'] > 0.9:
                metrics['overall_expert_rating'] = 'EXPERT_MASTER'
            elif metrics['expertise_score'] > 0.8:
                metrics['overall_expert_rating'] = 'EXPERT_ADVANCED'
            elif metrics['expertise_score'] > 0.7:
                metrics['overall_expert_rating'] = 'EXPERT_INTERMEDIATE'
            else:
                metrics['overall_expert_rating'] = 'EXPERT_BASIC'
            
            # 7. Recomenda√ß√µes
            if metrics['expertise_score'] > 0.85:
                metrics['recommendations'].append('‚úÖ Excelente aplica√ß√£o de expertise - m√≥dulos prontos para uso')
            else:
                metrics['recommendations'].append('üîß Considerar refinamento adicional para maximizar expertise')
            
            if metrics['synthesis_integration_score'] < 0.7:
                metrics['recommendations'].append('üîó Melhorar integra√ß√£o com Synthesis Engine')
            
            if metrics['coherence_achievement'] < 0.8:
                metrics['recommendations'].append('üéØ Fortalecer coer√™ncia entre m√≥dulos')
            
            return metrics
            
        except Exception as e:
            logger.error(f"‚ùå Erro no c√°lculo de m√©tricas expert: {e}")
            return {}

# Exemplo de como executar o processador (para fins de teste)
async def main():
    print("Executando o EnhancedModuleProcessor em modo de teste.")
    processor = EnhancedModuleProcessor()
    
    # Simular dados base para uma sess√£o de teste
    session_id = f"test_session_{datetime.now().strftime('%Y%m%d%H%M%S')}"
    test_data_dir = BASE_DATA_DIR / session_id
    test_data_dir.mkdir(parents=True, exist_ok=True)

    contexto_estrategico = {
        "tema": "Lan√ßamento de um novo caf√© especial gourmet",
        "segmento": "Consumidores de caf√© de alta qualidade no Brasil",
        "publico_alvo": "Jovens profissionais, apreciadores de caf√©, que buscam uma experi√™ncia premium e valorizam a origem e a sustentabilidade do produto.",
        "diferenciais": ["Gr√£os 100% ar√°bica de origem √∫nica", "Torra artesanal", "Embalagem sustent√°vel"],
        "objetivo": "Se tornar a marca de caf√© especial preferida pelo p√∫blico jovem profissional em 2 anos."
    }

    with open(test_data_dir / "contexto_estrategico.json", 'w', encoding='utf-8') as f:
        json.dump(contexto_estrategico, f, indent=4, ensure_ascii=False)

    # Executar a gera√ß√£o de todos os m√≥dulos
    results = await processor.generate_all_modules(session_id)
    print("\nResultados da Gera√ß√£o:")
    print(json.dumps(results, indent=2))

if __name__ == "__main__":
    # Para executar este script diretamente, descomente a linha abaixo
    # asyncio.run(main())
    logger.info("Script enhanced_module_processor.py carregado. Para execu√ß√£o de teste, chame a fun√ß√£o main().")




# Inst√¢ncia global do processador para ser importada por outros m√≥dulos
enhanced_module_processor = EnhancedModuleProcessor()

